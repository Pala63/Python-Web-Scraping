{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pala63/Python-Web-Scraping/blob/main/lessons/02_web_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv9hp2dpaykf"
      },
      "source": [
        "# Web Scraping with Beautiful Soup\n",
        "\n",
        "* * *\n",
        "\n",
        "### Icons used in this notebook\n",
        "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
        "ü•ä **Challenge**: Interactive exercise. We'll work through these in the workshop!<br>\n",
        "‚ö†Ô∏è **Warning**: Heads-up about tricky stuff or common mistakes.<br>\n",
        "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
        "üé¨ **Demo**: Showing off something more advanced ‚Äì so you know what Python can be used for!<br>\n",
        "\n",
        "### Learning Objectives\n",
        "1. [Reflection: To Scape Or Not To Scrape](#when)\n",
        "2. [Extracting and Parsing HTML](#extract)\n",
        "3. [Scraping the Illinois General Assembly](#scrape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt1hHE_Zaykg"
      },
      "source": [
        "<a id='when'></a>\n",
        "\n",
        "# To Scrape Or Not To Scrape\n",
        "\n",
        "When we'd like to access data from the web, we first have to make sure if the website we are interested in offers a Web API. Platforms like Twitter, Reddit, and the New York Times offer APIs. **Check out D-Lab's [Python Web APIs](https://github.com/dlab-berkeley/Python-Web-APIs) workshop if you want to learn how to use APIs.**\n",
        "\n",
        "However, there are often cases when a Web API does not exist. In these cases, we may have to resort to web scraping, where we extract the underlying HTML from a web page, and directly obtain the information we want. There are several packages in Python we can use to accomplish these tasks. We'll focus two packages: Requests and Beautiful Soup.\n",
        "\n",
        "Our case study will be scraping information on the [state senators of Illinois](http://www.ilga.gov/senate), as well as the [list of bills](http://www.ilga.gov/senate/SenatorBills.asp?MemberID=1911&GA=98&Primary=True) each senator has sponsored. Before we get started, peruse these websites to take a look at their structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr6cnroLaykh"
      },
      "source": [
        "## Installation\n",
        "\n",
        "We will use two main packages: [Requests](http://docs.python-requests.org/en/latest/user/quickstart/) and [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/bs4/doc/). Go ahead and install these packages, if you haven't already:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YhGYt51ayki",
        "outputId": "343bc18a-4e70-4d57-9f8c-4cdb0696c3e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n"
          ]
        }
      ],
      "source": [
        "%pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Lf8sEAVayki",
        "outputId": "b815d60e-97ae-4632-d099-5497140486ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW_9U91Raykj"
      },
      "source": [
        "We'll also install the `lxml` package, which helps support some of the parsing that Beautiful Soup performs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HNe9S_eaykj",
        "outputId": "894bdb2f-4322-4845-87b1-5f33bec8fb78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.4.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "tags": [],
        "id": "xbx41q7kaykk"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import requests\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh05WKFCaykk"
      },
      "source": [
        "<a id='extract'></a>\n",
        "\n",
        "# Extracting and Parsing HTML\n",
        "\n",
        "In order to succesfully scrape and analyse HTML, we'll be going through the following 4 steps:\n",
        "1. Make a GET request\n",
        "2. Parse the page with Beautiful Soup\n",
        "3. Search for HTML elements\n",
        "4. Get attributes and text of these elements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0R-SJbZaykk"
      },
      "source": [
        "## Step 1: Make a GET Request to Obtain a Page's HTML\n",
        "\n",
        "We can use the Requests library to:\n",
        "\n",
        "1. Make a GET request to the page, and\n",
        "2. Read in the webpage's HTML code.\n",
        "\n",
        "The process of making a request and obtaining a result resembles that of the Web API workflow. Now, however, we're making a request directly to the website, and we're going to have to parse the HTML ourselves. This is in contrast to being provided data organized into a more straightforward `JSON` or `XML` output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riweKZSPaykl",
        "outputId": "40101749-afe3-4638-c46f-90714f5b3425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\r\n",
            "<html lang=\"en\">\r\n",
            "<head id=\"Head1\">\r\n",
            "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\r\n",
            "    <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\" />\r\n",
            "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\r\n",
            "    <meta charset=\"utf-8\" />\r\n",
            "    <meta charset=\"UTF-8\">\r\n",
            "    <!-- Meta Description -->\r\n",
            "    <meta name=\"description\" content=\"Welcome to the official government website of the Illinois General Assembly\">\r\n",
            "    <meta name=\"contactName\" content=\"Legislative Information System\">\r\n",
            "    <meta name=\"contactOrganization\" content=\"LIS Staff Services\">\r\n",
            "    <meta name=\"contactStreetAddress1\" content=\"705 Stratton Office Building\">\r\n",
            "    <meta name=\"contactCity\" content=\"Springfield\">\r\n",
            "    <meta name=\"contactZipcode\" content=\"62706\">\r\n",
            "    <meta name=\"contactNetworkAddress\" content=\"webmaster@ilga.gov\">\r\n",
            "    <meta name=\"contactPhoneNumber\" content=\"217-782-3944\">\r\n",
            "    <meta name=\"contactFaxNumber\" content=\"217-524-6059\">\r\n",
            "    <meta name\n"
          ]
        }
      ],
      "source": [
        "# Make a GET request\n",
        "req = requests.get('http://www.ilga.gov/Senate/Members')\n",
        "# Read the content of the server‚Äôs response\n",
        "src = req.text\n",
        "# View some output\n",
        "print(src[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta celda se hace una solicitud HTTP (GET) a la p√°gina del Senado del estado de Illinois usando la librer√≠a requests.\n",
        "Luego se guarda el contenido HTML de la p√°gina en la variable src.\n",
        "Finalmente, se imprimen los primeros 1000 caracteres del HTML para ver c√≥mo est√° estructurado el c√≥digo de esa p√°gina web."
      ],
      "metadata": {
        "id": "f6ZNhj87dDQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¬øPor qu√© hacemos esto?\n",
        "Para hacer scraping, necesitamos primero ver c√≥mo est√° estructurado el HTML, ya que es ah√≠ donde est√° la informaci√≥n que queremos extraer. En este caso, la p√°gina del Senado tiene los nombres y enlaces a los senadores, y lo vamos a capturar desde el HTML directamente."
      ],
      "metadata": {
        "id": "sH8X-oGpdF5y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I246VDrtaykl"
      },
      "source": [
        "## Step 2: Parse the Page with Beautiful Soup\n",
        "\n",
        "Now, we use the `BeautifulSoup` function to parse the reponse into an HTML tree. This returns an object (called a **soup object**) which contains all of the HTML in the original document.\n",
        "\n",
        "If you run into an error about a parser library, make sure you've installed the `lxml` package to provide Beautiful Soup with the necessary parsing tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_2Y3Gg8aykl",
        "outputId": "42f6fe71-3d40-41fd-8017-b671829677e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            " <head id=\"Head1\">\n",
            "  <meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
            "  <meta content=\"text/html;charset=utf-8\" http-equiv=\"content-type\"/>\n",
            "  <meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <!-- Meta Description -->\n",
            "  <meta content=\"Welcome to the official government website of the Illinois General Assembly\" name=\"description\"/>\n",
            "  <meta content=\"Legislative Information System\" name=\"contactName\"/>\n",
            "  <meta content=\"LIS Staff Services\" name=\"contactOrganization\"/>\n",
            "  <meta content=\"705 Stratton Office Building\" name=\"contactStreetAddress1\"/>\n",
            "  <meta content=\"Springfield\" name=\"contactCity\"/>\n",
            "  <meta content=\"62706\" name=\"contactZipcode\"/>\n",
            "  <meta content=\"webmaster@ilga.gov\" name=\"contactNetworkAddress\"/>\n",
            "  <meta content=\"217-782-3944\" name=\"contactPhoneNumber\"/>\n",
            "  <meta content=\"217-524-6059\" name=\"contactFaxNumber\"/>\n",
            "  <meta content=\"State Of Illinois\" name=\"originatorJur\n"
          ]
        }
      ],
      "source": [
        "# Parse the response into an HTML tree\n",
        "soup = BeautifulSoup(src, 'lxml')\n",
        "# Take a look\n",
        "print(soup.prettify()[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se convierte el contenido HTML (src) en un objeto BeautifulSoup.\n",
        "Esto permite navegar y buscar informaci√≥n dentro del HTML como si fuera un √°rbol estructurado.\n",
        "Se usa 'lxml' como el parser porque es r√°pido y eficiente.\n",
        "La funci√≥n prettify() muestra el HTML con sangr√≠as, facilitando su lectura.\n",
        "Aqu√≠ solo se imprimen los primeros 1000 caracteres para no saturar la salida"
      ],
      "metadata": {
        "id": "pD1zHBLfe78T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "allgNE4Haykl"
      },
      "source": [
        "The output looks pretty similar to the above, but now it's organized in a `soup` object which allows us to more easily traverse the page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5iVlTqGaykm"
      },
      "source": [
        "## Step 3: Search for HTML Elements\n",
        "\n",
        "Beautiful Soup has a number of functions to find useful components on a page. Beautiful Soup lets you find elements by their:\n",
        "\n",
        "1. HTML tags\n",
        "2. HTML Attributes\n",
        "3. CSS Selectors\n",
        "\n",
        "Let's search first for **HTML tags**.\n",
        "\n",
        "The function `find_all` searches the `soup` tree to find all the elements with an a particular HTML tag, and returns all of those elements.\n",
        "\n",
        "What does the example below do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtWgLa0raykm",
        "outputId": "dadcc916-41d7-4e9f-8bb8-deade2492fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"en\" href=\"#\">\n",
            "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-us\"></span> English\r\n",
            "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"af\" href=\"#\">\n",
            "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-za\"></span> Afrikaans\r\n",
            "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"sq\" href=\"#\">\n",
            "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-al\"></span> Albanian\r\n",
            "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"ar\" href=\"#\">\n",
            "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-ae\"></span> Arabic\r\n",
            "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"hy\" href=\"#\">\n",
            "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-am\"></span> Armenian\r\n",
            "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"az\" href=\"#\">\n",
            "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-az\"></span> Azerbaijani\r\n",
            "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"eu\" href=\"#\">\n",
            "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-eu\"></span> Basque\r\n",
            "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"bn\" href=\"#\">\n",
            "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-bd\"></span> Bengali\r\n",
            "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"bs\" href=\"#\">\n",
            "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-ba\"></span> Bosnian\r\n",
            "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"ca\" href=\"#\">\n",
            "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-es\"></span> Catalan\r\n",
            "                            </a>]\n"
          ]
        }
      ],
      "source": [
        "# Find all elements with a certain tag\n",
        "a_tags = soup.find_all(\"a\")\n",
        "print(a_tags[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se buscan todas las etiquetas <a> en la p√°gina (que normalmente representan enlaces).\n",
        "find_all(\"a\") devuelve una lista con todos los elementos <a>.\n",
        "Se imprimen los primeros 10 resultados para ver c√≥mo lucen.\n",
        "Esto es √∫til para ver a qu√© p√°ginas est√°n enlazando (como los senadores en este caso)."
      ],
      "metadata": {
        "id": "MwTwfyTbfD7Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8wSEkyaaykm"
      },
      "source": [
        "Because `find_all()` is the most popular method in the Beautiful Soup search API, you can use a shortcut for it. If you treat the BeautifulSoup object as though it were a function, then it‚Äôs the same as calling `find_all()` on that object.\n",
        "\n",
        "These two lines of code are equivalent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwUeNdBLaykm",
        "outputId": "b70169ba-e093-4e00-b917-d8d941f8f844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"en\" href=\"#\">\n",
            "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-us\"></span> English\r\n",
            "                            </a>\n",
            "<a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"en\" href=\"#\">\n",
            "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-us\"></span> English\r\n",
            "                            </a>\n"
          ]
        }
      ],
      "source": [
        "a_tags = soup.find_all(\"a\")\n",
        "a_tags_alt = soup(\"a\")\n",
        "print(a_tags[0])\n",
        "print(a_tags_alt[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estas dos formas (soup.find_all(\"a\") y soup(\"a\")) hacen exactamente lo mismo.\n",
        "Ambas devuelven una lista con todos los elementos <a> del HTML.\n",
        "Se imprimen los primeros elementos de ambas listas para mostrar que son iguales."
      ],
      "metadata": {
        "id": "Yi4Q-j5Mfa5J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp9MWMlxaykm"
      },
      "source": [
        "How many links did we obtain?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBHor_EUaykm",
        "outputId": "d5d15a63-556c-4cd4-95ca-d2f55230249a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270\n"
          ]
        }
      ],
      "source": [
        "print(len(a_tags))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se imprime la cantidad total de etiquetas <a> encontradas en la p√°gina.\n",
        "Generalmente habr√° muchos enlaces, y no todos ser√°n √∫tiles para tu objetivo."
      ],
      "metadata": {
        "id": "hCmYlcF0fgqa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ct9A120aykm"
      },
      "source": [
        "That's a lot! Many elements on a page will have the same HTML tag. For instance, if you search for everything with the `a` tag, you're likely to get more hits, many of which you might not want. Remember, the `a` tag defines a hyperlink, so you'll usually find many on any given page.\n",
        "\n",
        "What if we wanted to search for HTML tags with certain attributes, such as particular CSS classes?\n",
        "\n",
        "We can do this by adding an additional argument to the `find_all`. In the example below, we are finding all the `a` tags, and then filtering those with `class_=\"sidemenu\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvRmiG0yaykm",
        "outputId": "a0491a17-f12c-4995-81eb-32720ee5fcfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<a class=\"notranslate\" href=\"/Senate/Members/Details/3312\">Neil Anderson</a>,\n",
              " <a class=\"notranslate\" href=\"/Senate/Members/Details/3312\">Neil Anderson</a>]"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ],
      "source": [
        "# Get only the 'a' tags in 'sidemenu' class\n",
        "side_menus = soup(\"a\", class_=\"notranslate\")\n",
        "side_menus[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se filtran los enlaces <a> que tienen el atributo class=\"sidemenu\".\n",
        "Esto es √∫til para obtener solo los enlaces que forman parte del men√∫ lateral de navegaci√≥n"
      ],
      "metadata": {
        "id": "Y_iwg8Ygfvwz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUgT5t3Laykm"
      },
      "source": [
        "A more efficient way to search for elements on a website is via a **CSS selector**. For this we have to use a different method called `select()`. Just pass a string into the `.select()` to get all elements with that string as a valid CSS selector.\n",
        "\n",
        "In the example above, we can use `\"a.sidemenu\"` as a CSS selector, which returns all `a` tags with class `sidemenu`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF7JSZjMaykm",
        "outputId": "c51eb033-f3ba-4969-e820-80e962a3f9e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<div class=\"member-overlay\">\n",
              " <h5 class=\"card-title\"><a class=\"notranslate\" href=\"/Senate/Members/Details/3312\">Neil Anderson</a> (R)</h5>\n",
              " <p class=\"card-text\">\n",
              "                                             Republican Caucus Chair\n",
              "                                             <br/>47th District\n",
              "                                         </p>\n",
              " </div>,\n",
              " <div class=\"member-overlay\">\n",
              " <h5 class=\"card-title\"><a class=\"notranslate\" href=\"/Senate/Members/Details/3312\">Neil Anderson</a> (R)</h5>\n",
              " <p class=\"card-text\">\n",
              "                                             Republican Caucus Chair\n",
              "                                             <br/>47th District\n",
              "                                         </p>\n",
              " </div>,\n",
              " <div class=\"member-overlay\">\n",
              " <h5 class=\"card-title\"><a class=\"notranslate\" href=\"/Senate/Members/Details/3316\">Omar Aquino</a> (D)</h5>\n",
              " <p class=\"card-text\">\n",
              "                                             Majority Caucus Chair\n",
              "                                             <br/>2nd District\n",
              "                                         </p>\n",
              " </div>,\n",
              " <div class=\"member-overlay\">\n",
              " <h5 class=\"card-title\"><a class=\"notranslate\" href=\"/Senate/Members/Details/3316\">Omar Aquino</a> (D)</h5>\n",
              " <p class=\"card-text\">\n",
              "                                             Majority Caucus Chair\n",
              "                                             <br/>2nd District\n",
              "                                         </p>\n",
              " </div>,\n",
              " <div class=\"member-overlay\">\n",
              " <h5 class=\"card-title\"><a class=\"notranslate\" href=\"/Senate/Members/Details/3383\">Li Arellano, Jr.</a> (R)</h5>\n",
              " <p class=\"card-text\">\n",
              "                                             Senator\n",
              "                                             <br/>37th District\n",
              "                                         </p>\n",
              " </div>]"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ],
      "source": [
        "# Get elements with \"a.sidemenu\" CSS Selector.\n",
        "selected = soup.select(\"div.member-overlay\")\n",
        "selected[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra forma m√°s eficiente de buscar elementos es con selectores CSS.\n",
        "\"a.sidemenu\" selecciona todas las etiquetas <a> que tienen la clase sidemenu.\n",
        "Se imprimen los primeros 5 elementos encontrados.\n",
        "Este m√©todo es muy flexible y permite b√∫squedas complejas como \"div > ul > li > a\"."
      ],
      "metadata": {
        "id": "Td4kTZ0Gf5Ci"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUK-02Rlaykn"
      },
      "source": [
        "## ü•ä Challenge: Find All\n",
        "\n",
        "Use BeautifulSoup to find all the `a` elements with class `mainmenu`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "XHcp0KYqaykn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc41dab-5722-4659-8f4d-ecb657d30afc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<a aria-expanded=\"false\" aria-haspopup=\"true\" b-0yw6sxot5c=\"\" data-toggle=\"dropdown\" href=\"/Legislation\" role=\"button\">\n",
              " <span b-0yw6sxot5c=\"\">LEGISLATION &amp; LAWS</span> <i b-0yw6sxot5c=\"\" class=\"fa fa-chevron-down\"></i>\n",
              " </a>,\n",
              " <a b-0yw6sxot5c=\"\" href=\"/Legislation\">Bills &amp; Resolutions</a>]"
            ]
          },
          "metadata": {},
          "execution_count": 263
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "side_menus = soup.find_all(\"a\", href=\"/Legislation\")\n",
        "side_menus[:10]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTVTSkeCaykn"
      },
      "source": [
        "## Step 4: Get Attributes and Text of Elements\n",
        "\n",
        "Once we identify elements, we want the access information in that element. Usually, this means two things:\n",
        "\n",
        "1. Text\n",
        "2. Attributes\n",
        "\n",
        "Getting the text inside an element is easy. All we have to do is use the `text` member of a `tag` object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIT-mQCjaykn",
        "outputId": "b01755a6-c008-48c1-aa9e-973240e3fa19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a class=\"notranslate\" href=\"/Senate/Members/Details/3312\">Neil Anderson</a>\n",
            "Class:  <class 'bs4.element.Tag'>\n"
          ]
        }
      ],
      "source": [
        "# Get all sidemenu links as a list\n",
        "side_menu_links = soup.select(\"a.notranslate\")\n",
        "\n",
        "# Examine the first link\n",
        "first_link = side_menu_links[0]\n",
        "print(first_link)\n",
        "\n",
        "# What class is this variable?\n",
        "print('Class: ', type(first_link))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwiVkaWSaykn"
      },
      "source": [
        "It's a Beautiful Soup tag! This means it has a `text` member:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss0PDls9aykn",
        "outputId": "fa39c08f-c2d9-4ace-e83e-7390b25297e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neil Anderson\n"
          ]
        }
      ],
      "source": [
        "print(first_link.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto es interesante por que ignora las etiquetas html y me devuelve solo el texto."
      ],
      "metadata": {
        "id": "lMREBHMklsEK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9PqtAjuaykn"
      },
      "source": [
        "Sometimes we want the value of certain attributes. This is particularly relevant for `a` tags, or links, where the `href` attribute tells us where the link goes.\n",
        "\n",
        "üí° **Tip**: You can access a tag‚Äôs attributes by treating the tag like a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTbS6q7saykn",
        "outputId": "ac650628-bab8-4118-93d5-a6f91e77d625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/Senate/Members/Details/3312\n"
          ]
        }
      ],
      "source": [
        "print(first_link['href'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjtdwO_qaykn"
      },
      "source": [
        "## ü•ä Challenge: Extract specific attributes\n",
        "\n",
        "Extract all `href` attributes for each `mainmenu` URL."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(soup.prettify()[:500])  # Solo los primeros 500 caracteres para no saturar\n"
      ],
      "metadata": {
        "id": "AkcqqgdJniN8",
        "outputId": "eda2d533-c6e8-4836-8164-68a0d04be04d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "<html lang=\"en\">\n",
            " <head id=\"Head1\">\n",
            "  <meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
            "  <meta content=\"text/html;charset=utf-8\" http-equiv=\"content-type\"/>\n",
            "  <meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <meta charset=\"utf-8\"/>\n",
            "  <!-- Meta Description -->\n",
            "  <meta content=\"Welcome to the official government website of the Illinois General Assembly\" name=\"description\"/>\n",
            "  <meta content=\"Legislative Information System\" nam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvTmur5Gaykn",
        "outputId": "2904b0f5-ac08-4d3f-b06f-e319a842eae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/Senate/Members/Details/3312', '/Senate/Members/Details/3312', '/Senate/Members/Details/3316', '/Senate/Members/Details/3316', '/Senate/Members/Details/3383', '/Senate/Members/Details/3383', '/Senate/Members/Details/3413', '/Senate/Members/Details/3413', '/Senate/Members/Details/3337', '/Senate/Members/Details/3337', '/Senate/Members/Details/3386', '/Senate/Members/Details/3386', '/Senate/Members/Details/3317', '/Senate/Members/Details/3317', '/Senate/Members/Details/3403', '/Senate/Members/Details/3403', '/Senate/Members/Details/3410', '/Senate/Members/Details/3410', '/Senate/Members/Details/3443', '/Senate/Members/Details/3443', '/Senate/Members/Details/3291', '/Senate/Members/Details/3291', '/Senate/Members/Details/3329', '/Senate/Members/Details/3329', '/Senate/Members/Details/3334', '/Senate/Members/Details/3334', '/Senate/Members/Details/3407', '/Senate/Members/Details/3407', '/Senate/Members/Details/3339', '/Senate/Members/Details/3339', '/Senate/Members/Details/3412', '/Senate/Members/Details/3412', '/Senate/Members/Details/3376', '/Senate/Members/Details/3376', '/Senate/Members/Details/3338', '/Senate/Members/Details/3338', '/Senate/Members/Details/3318', '/Senate/Members/Details/3318', '/Senate/Members/Details/3341', '/Senate/Members/Details/3341', '/Senate/Members/Details/3442', '/Senate/Members/Details/3442', '/Senate/Members/Details/3408', '/Senate/Members/Details/3408', '/Senate/Members/Details/3268', '/Senate/Members/Details/3268', '/Senate/Members/Details/3292', '/Senate/Members/Details/3292', '/Senate/Members/Details/3411', '/Senate/Members/Details/3411', '/Senate/Members/Details/3293', '/Senate/Members/Details/3293', '/Senate/Members/Details/3460', '/Senate/Members/Details/3460', '/Senate/Members/Details/3270', '/Senate/Members/Details/3270', '/Senate/Members/Details/3269', '/Senate/Members/Details/3269', '/Senate/Members/Details/3378', '/Senate/Members/Details/3378', '/Senate/Members/Details/3276', '/Senate/Members/Details/3276', '/Senate/Members/Details/3372', '/Senate/Members/Details/3372', '/Senate/Members/Details/3271', '/Senate/Members/Details/3271', '/Senate/Members/Details/3406', '/Senate/Members/Details/3406', '/Senate/Members/Details/3264', '/Senate/Members/Details/3264', '/Senate/Members/Details/3380', '/Senate/Members/Details/3380', '/Senate/Members/Details/3369', '/Senate/Members/Details/3369', '/Senate/Members/Details/3342', '/Senate/Members/Details/3342', '/Senate/Members/Details/3294', '/Senate/Members/Details/3294', '/Senate/Members/Details/3313', '/Senate/Members/Details/3313', '/Senate/Members/Details/3343', '/Senate/Members/Details/3343', '/Senate/Members/Details/3344', '/Senate/Members/Details/3344', '/Senate/Members/Details/3404', '/Senate/Members/Details/3404', '/Senate/Members/Details/3405', '/Senate/Members/Details/3405', '/Senate/Members/Details/3281', '/Senate/Members/Details/3281', '/Senate/Members/Details/3295', '/Senate/Members/Details/3295', '/Senate/Members/Details/3398', '/Senate/Members/Details/3398', '/Senate/Members/Details/3331', '/Senate/Members/Details/3331', '/Senate/Members/Details/3296', '/Senate/Members/Details/3296', '/Senate/Members/Details/3265', '/Senate/Members/Details/3265', '/Senate/Members/Details/3319', '/Senate/Members/Details/3319', '/Senate/Members/Details/3399', '/Senate/Members/Details/3399', '/Senate/Members/Details/3397', '/Senate/Members/Details/3397', '/Senate/Members/Details/3409', '/Senate/Members/Details/3409', '/Senate/Members/Details/3385', '/Senate/Members/Details/3385', '/Senate/Members/Details/3375', '/Senate/Members/Details/3375', '/Senate/Members/Details/3345', '/Senate/Members/Details/3345', '/Senate/Members/Details/3449', '/Senate/Members/Details/3449', '/Senate/Members/Details/3336', '/Senate/Members/Details/3336', '/Senate/Members/Details/3315', '/Senate/Members/Details/3315']\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "# Buscar todos los enlaces con clase 'dropdown-item'\n",
        "no_translate = soup.find_all('a', class_='notranslate')\n",
        "\n",
        "# Extraer sus atributos href\n",
        "dropdown_hrefs = [link['href'] for link in no_translate]\n",
        "\n",
        "# Mostrar resultados\n",
        "print(dropdown_hrefs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO6FgGQsaykn"
      },
      "source": [
        "<a id='scrape'></a>\n",
        "\n",
        "# Scraping the Illinois General Assembly\n",
        "\n",
        "Believe it or not, those are really the fundamental tools you need to scrape a website. Once you spend more time familiarizing yourself with HTML and CSS, then it's simply a matter of understanding the structure of a particular website and intelligently applying the tools of Beautiful Soup and Python.\n",
        "\n",
        "Let's apply these skills to scrape the [Illinois 98th General Assembly](http://www.ilga.gov/senate/default.asp?GA=98).\n",
        "\n",
        "Specifically, our goal is to scrape information on each senator, including their name, district, and party."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g-GlJx1aykn"
      },
      "source": [
        "## Scrape and Soup the Webpage\n",
        "\n",
        "Let's scrape and parse the webpage, using the tools we learned in the previous section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "tags": [],
        "id": "vrsL8XP4aykn"
      },
      "outputs": [],
      "source": [
        "# Make a GET request\n",
        "req = requests.get('https://ilga.gov/Legislation/BillStatus?DocNum=818&DocTypeID=HR&GA=101&GAID=9&LegID=34456&SessionID=51')\n",
        "# Read the content of the server‚Äôs response\n",
        "src = req.text\n",
        "# Soup it\n",
        "soup = BeautifulSoup(src, \"lxml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_dXALAcaykn"
      },
      "source": [
        "## Search for the Table Elements\n",
        "\n",
        "Our goal is to obtain the elements in the table on the webpage. Remember: rows are identified by the `tr` tag. Let's use `find_all` to obtain these elements."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uKcc4dSLXVjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WEB DINAMICA**\n",
        "\n",
        "Al realizar un scraping de la p√°gina https://ilga.gov/Legislation/BillStatus?... utilizando requests y BeautifulSoup, me encontr√© con un problema: la b√∫squeda de elementos <tr> (filas de tabla) devolv√≠a una lista vac√≠a. Esto se debe a que la p√°gina carga su contenido de forma din√°mica utilizando JavaScript.\n",
        "\n",
        "Cuando utilizamos requests.get(...), lo que se descarga es √∫nicamente el HTML est√°tico que el servidor entrega inicialmente. Sin embargo, en este caso, la tabla que contiene los datos no se encuentra en ese HTML original, sino que es generada posteriormente por JavaScript una vez que la p√°gina ha sido completamente cargada en el navegador. Como requests no tiene la capacidad de ejecutar c√≥digo JavaScript, dicha tabla simplemente no aparece en el contenido descargado.\n",
        "\n",
        "Por esta raz√≥n, decid√≠ utilizar Selenium, una herramienta que permite simular el comportamiento de un navegador real (como Chrome o Firefox). Selenium s√≠ ejecuta JavaScript, lo que permite acceder al contenido completo de la p√°gina, incluyendo los datos generados din√°micamente. Gracias a esto, fue posible capturar el HTML final ya renderizado y, a partir de √©l, utilizar BeautifulSoup para encontrar correctamente todas las filas <tr> que componen la tabla deseada."
      ],
      "metadata": {
        "id": "tQ-4ervtYMFP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "id": "ZYJAd0lTayko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a838ff9-d9cc-4208-bd75-c0d63c906619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¬øHay '<tr>' en el HTML descargado? False\n",
            "Primeros 500 caracteres:\n",
            " <!DOCTYPE html>\r\n",
            "<html lang=\"en\">\r\n",
            "<head id=\"Head1\">\r\n",
            "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\r\n",
            "    <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\" />\r\n",
            "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\r\n",
            "    <meta charset=\"utf-8\" />\r\n",
            "    <meta charset=\"UTF-8\">\r\n",
            "    <!-- Meta Description -->\r\n",
            "    <meta name=\"description\" content=\"Welcome to the official government website of the Illinois General Assembly\">\r\n",
            "    <meta name=\"contactName\n"
          ]
        }
      ],
      "source": [
        "# Get all table row elements\n",
        "rows = soup.find_all(\"tr\")\n",
        "len(rows)\n",
        "print(\"¬øHay '<tr>' en el HTML descargado?\", \"<tr\" in src)\n",
        "print(\"Primeros 500 caracteres:\\n\", src[:500])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNPusgIzWtOB",
        "outputId": "c0b37c9b-c1ce-481f-e69b-071feb8e856f"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.34.2)\n",
            "Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.7.14)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options # Import Options\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "# Set up Chrome options\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--no-sandbox') # Add this argument\n",
        "chrome_options.add_argument('--headless') # Add this argument for running without a visible browser\n",
        "chrome_options.add_argument('--disable-dev-shm-usage') # Add this argument\n",
        "\n",
        "# Crear el navegador\n",
        "driver = webdriver.Chrome(options=chrome_options) # Pass the options\n",
        "\n",
        "try:\n",
        "    # Cargar la p√°gina\n",
        "    driver.get('https://ilga.gov/Legislation/BillStatus?DocNum=818&DocTypeID=HR&GA=101&GAID=9&LegID=34456&SessionID=51')\n",
        "\n",
        "    # Esperar unos segundos para que cargue el contenido din√°mico\n",
        "    time.sleep(5)\n",
        "\n",
        "    # Obtener el HTML ya renderizado con JavaScript\n",
        "    html = driver.page_source\n",
        "\n",
        "    # Analizar con BeautifulSoup\n",
        "    soup = BeautifulSoup(html, 'lxml')\n",
        "\n",
        "    # Buscar filas de tabla\n",
        "    rows = soup.find_all(\"tr\")\n",
        "    print(f\"N√∫mero de filas encontradas: {len(rows)}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "finally:\n",
        "    driver.quit() # Ensure the driver is closed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NUOnkbbWrFE",
        "outputId": "53c63375-f118-4d36-850b-8650a3dc590d"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de filas encontradas: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta76lBefayks"
      },
      "source": [
        "‚ö†Ô∏è **Warning**: Keep in mind: `find_all` gets *all* the elements with the `tr` tag. We only want some of them. If we use the 'Inspect' function in Google Chrome and look carefully, then we can use some CSS selectors to get just the rows we're interested in. Specifically, we want the inner rows of the table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "id": "1pXM9KmUayks"
      },
      "outputs": [],
      "source": [
        "# Returns every ‚Äòtr tr tr‚Äô css selector in the page\n",
        "# rows = soup.select('tr tr tr')\n",
        "\n",
        "# for row in rows[:5]:\n",
        "    #print(row, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este codigo no encuentra etiquetas anidadas dentro de otras tr tres niveles profundos."
      ],
      "metadata": {
        "id": "yBInLxS4bQED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = soup.select('table tr')  # Todas las filas dentro de cualquier tabla\n",
        "print(f\"N√∫mero de filas encontradas: {len(rows)}\")\n",
        "\n",
        "if rows:\n",
        "    for row in rows[:5]:\n",
        "        print(row.prettify(), '\\n')\n",
        "else:\n",
        "    print(\"No se encontraron filas <tr> en la p√°gina.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kwXhGYlZ9Ce",
        "outputId": "4d97d6c6-dfa6-4d38-cf3d-9ea535c65e88"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de filas encontradas: 18\n",
            "<tr>\n",
            " <th>\n",
            "  Date\n",
            " </th>\n",
            " <th>\n",
            "  Chamber\n",
            " </th>\n",
            " <th>\n",
            "  Action\n",
            " </th>\n",
            "</tr>\n",
            " \n",
            "\n",
            "<tr>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "  11/02/2007\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "  House\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "  Filed with the Clerk by\n",
            "  <a href=\"../../house/members/details/1307\">\n",
            "   Rep. Daniel V. Beiser\n",
            "  </a>\n",
            " </td>\n",
            "</tr>\n",
            " \n",
            "\n",
            "<tr>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "  11/07/2007\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "  House\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "  Added Chief Co-Sponsor\n",
            "  <a href=\"../../house/members/details/1291\">\n",
            "   Rep. John E. Bradley\n",
            "  </a>\n",
            " </td>\n",
            "</tr>\n",
            " \n",
            "\n",
            "<tr>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "  11/07/2007\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "  House\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "  Added Chief Co-Sponsor\n",
            "  <a href=\"../../house/members/details/1286\">\n",
            "   Rep. Robert F. Flider\n",
            "  </a>\n",
            " </td>\n",
            "</tr>\n",
            " \n",
            "\n",
            "<tr>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "  11/07/2007\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "  House\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "  Added Chief Co-Sponsor\n",
            "  <a href=\"../../house/members/details/1347\">\n",
            "   Rep. Elizabeth Hernandez\n",
            "  </a>\n",
            " </td>\n",
            "</tr>\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "118qTAcYaykt"
      },
      "source": [
        "It looks like we want everything after the first two rows. Let's work with a single row to start, and build our loop from there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "id": "xxAE1PwMaykt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b42266b7-da38-4110-dfe6-3b16e4cde056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tr>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "  11/07/2007\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "  House\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "  Added Chief Co-Sponsor\n",
            "  <a href=\"../../house/members/details/1291\">\n",
            "   Rep. John E. Bradley\n",
            "  </a>\n",
            " </td>\n",
            "</tr>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example_row = rows[2]\n",
        "print(example_row.prettify())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este codigo imprime 3 filas 0 1 2"
      ],
      "metadata": {
        "id": "OW2jI0dicY4c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmdlipGnaykt"
      },
      "source": [
        "Let's break this row down into its component cells/columns using the `select` method with CSS selectors. Looking closely at the HTML, there are a couple of ways we could do this.\n",
        "\n",
        "* We could identify the cells by their tag `td`.\n",
        "* We could use the the class name `.detail`.\n",
        "* We could combine both and use the selector `td.detail`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "id": "UCSc-cTuaykt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8c1fa1-3b40-42b3-f134-333e5e63cddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "11/07/2007                                        </td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "House                                        </td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "Added Chief Co-Sponsor <a href=\"../../house/members/details/1291\">Rep. John E. Bradley</a></td>\n",
            "\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "11/07/2007                                        </td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "House                                        </td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "Added Chief Co-Sponsor <a href=\"../../house/members/details/1291\">Rep. John E. Bradley</a></td>\n",
            "\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "11/07/2007                                        </td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "House                                        </td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "Added Chief Co-Sponsor <a href=\"../../house/members/details/1291\">Rep. John E. Bradley</a></td>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for cell in example_row.select('td'):\n",
        "    print(cell)\n",
        "print()\n",
        "\n",
        "for cell in example_row.select('.content'):\n",
        "    print(cell)\n",
        "print()\n",
        "\n",
        "for cell in example_row.select('td.content'):\n",
        "    print(cell)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXCzwNv4aykt"
      },
      "source": [
        "We can confirm that these are all the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "tags": [],
        "id": "bmv_ZLMNaykt"
      },
      "outputs": [],
      "source": [
        "assert example_row.select('td') == example_row.select('.content') == example_row.select('td.content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8JqW7CBaykt"
      },
      "source": [
        "Let's use the selector `td.detail` to be as specific as possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "2-MeTwXwaykt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e2ead3-cdef-4610-91bd-ded824928511"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
              " 11/07/2007                                        </td>,\n",
              " <td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
              " House                                        </td>,\n",
              " <td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
              " Added Chief Co-Sponsor <a href=\"../../house/members/details/1291\">Rep. John E. Bradley</a></td>]"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ],
      "source": [
        "# Select only those 'td' tags with class 'detail'\n",
        "detail_cells = example_row.select('td.content')\n",
        "detail_cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI6Xp9uGaykt"
      },
      "source": [
        "Most of the time, we're interested in the actual **text** of a website, not its tags. Recall that to get the text of an HTML element, we use the `text` member:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "ZqvMUEuVaykt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310d232b-1ed9-4087-9981-3712e6117b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n11/07/2007                                        ', '\\nHouse                                        ', '\\nAdded Chief Co-Sponsor Rep. John E. Bradley']\n"
          ]
        }
      ],
      "source": [
        "# Keep only the text in each of those cells\n",
        "row_data = [cell.text for cell in detail_cells]\n",
        "\n",
        "print(row_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HsSsX1Zayku"
      },
      "source": [
        "Looks good! Now we just use our basic Python knowledge to get the elements of this list that we want. Remember, we want the senator's name, their district, and their party."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "ilhAkeHSayku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27868c5a-7357-4bb9-b863-c85e379a2c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "11/07/2007                                        \n",
            "\n",
            "House                                        \n",
            "\n",
            "Added Chief Co-Sponsor Rep. John E. Bradley\n"
          ]
        }
      ],
      "source": [
        "print(row_data[0]) # Name\n",
        "print(row_data[1]) # District\n",
        "print(row_data[2]) # Party"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr7W24AZayku"
      },
      "source": [
        "## Getting Rid of Junk Rows\n",
        "\n",
        "We saw at the beginning that not all of the rows we got actually correspond to a senator. We'll need to do some cleaning before we can proceed forward. Take a look at some examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "id": "XDLGr036ayku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd261ba-51a9-43b2-8caa-bbbeb006e2f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 0:\n",
            " <tr>\n",
            "<th>Date</th>\n",
            "<th>Chamber</th>\n",
            "<th>Action</th>\n",
            "</tr> \n",
            "\n",
            "Row 1:\n",
            " <tr>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "11/02/2007                                        </td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "House                                        </td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "Filed with the Clerk by <a href=\"../../house/members/details/1307\">Rep. Daniel V. Beiser</a></td></tr> \n",
            "\n",
            "Last Row:\n",
            " <tr>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "<b>5/19/2008</b>\n",
            "</td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "<b>House</b>\n",
            "</td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "<b>Tabled By Sponsor <a href=\"../../house/members/details/1307\">Rep. Daniel V. Beiser</a></b>\n",
            "</td></tr>\n"
          ]
        }
      ],
      "source": [
        "print('Row 0:\\n', rows[0], '\\n')\n",
        "print('Row 1:\\n', rows[1], '\\n')\n",
        "print('Last Row:\\n', rows[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9XSE5Auayku"
      },
      "source": [
        "When we write our for loop, we only want it to apply to the relevant rows. So we'll need to filter out the irrelevant rows. The way to do this is to compare some of these to the rows we do want, see how they differ, and then formulate that in a conditional.\n",
        "\n",
        "As you can imagine, there a lot of possible ways to do this, and it'll depend on the website. We'll show some here to give you an idea of how to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "id": "u02zzmG5ayku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "219ed99e-816b-493e-f7b3-d8a59fe0835a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "6\n",
            "6\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "# Bad rows\n",
        "print(len(rows[0]))\n",
        "print(len(rows[1]))\n",
        "\n",
        "# Good rows\n",
        "print(len(rows[2]))\n",
        "print(len(rows[3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExNEtUFKayku"
      },
      "source": [
        "Perhaps good rows have a length of 5. Let's check:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "id": "RaCkPerHayku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d58575-b3d9-41c6-a137-d7352dc42e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filas con 3 celdas encontradas: 17\n",
            "\n",
            "<tr>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "  11/02/2007\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "  House\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "  Filed with the Clerk by\n",
            "  <a href=\"../../house/members/details/1307\">\n",
            "   Rep. Daniel V. Beiser\n",
            "  </a>\n",
            " </td>\n",
            "</tr>\n",
            " \n",
            "\n",
            "<tr>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "  5/19/2008\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "  House\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "  Motion Prevailed\n",
            " </td>\n",
            "</tr>\n",
            " \n",
            "\n",
            "<tr>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "  <b>\n",
            "   5/19/2008\n",
            "  </b>\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "  <b>\n",
            "   House\n",
            "  </b>\n",
            " </td>\n",
            " <td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "  <b>\n",
            "   Tabled By Sponsor\n",
            "   <a href=\"../../house/members/details/1307\">\n",
            "    Rep. Daniel V. Beiser\n",
            "   </a>\n",
            "  </b>\n",
            " </td>\n",
            "</tr>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Filtrar filas con 3 celdas <td>\n",
        "good_rows = [row for row in rows if len(row.find_all('td')) == 3]\n",
        "\n",
        "print(f\"Filas con 3 celdas encontradas: {len(good_rows)}\\n\")\n",
        "\n",
        "# Mostrar la primera fila bien formada\n",
        "print(good_rows[0].prettify(), '\\n')\n",
        "\n",
        "# Mostrar la pen√∫ltima fila\n",
        "print(good_rows[-2].prettify(), '\\n')\n",
        "\n",
        "# Mostrar la √∫ltima fila\n",
        "print(good_rows[-1].prettify())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtgX9RDQayku"
      },
      "source": [
        "We found a footer row in our list that we'd like to avoid. Let's try something else:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "id": "N0pWf-2Zayku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a02fd694-5513-4e72-dffe-14fefb2a52d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
              " 11/07/2007                                        </td>,\n",
              " <td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
              " House                                        </td>,\n",
              " <td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
              " Added Chief Co-Sponsor <a href=\"../../house/members/details/1291\">Rep. John E. Bradley</a></td>]"
            ]
          },
          "metadata": {},
          "execution_count": 284
        }
      ],
      "source": [
        "rows[2].select('td.content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "7YP4AXOPayku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de63711f-9feb-40cb-90b9-887e391b46ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "<b>5/19/2008</b>\n",
            "</td>, <td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "<b>House</b>\n",
            "</td>, <td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "<b>Tabled By Sponsor <a href=\"../../house/members/details/1307\">Rep. Daniel V. Beiser</a></b>\n",
            "</td>] \n",
            "\n",
            "[<td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "11/07/2007                                        </td>, <td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "House                                        </td>, <td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "Added Chief Co-Sponsor <a href=\"../../house/members/details/1348\">Rep. Fred Crespo</a></td>] \n",
            "\n",
            "Checking rows...\n",
            "\n",
            "<tr>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "11/02/2007                                        </td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "House                                        </td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "Filed with the Clerk by <a href=\"../../house/members/details/1307\">Rep. Daniel V. Beiser</a></td></tr> \n",
            "\n",
            "<tr>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"13%\">\n",
            "<b>5/19/2008</b>\n",
            "</td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"12%\">\n",
            "<b>House</b>\n",
            "</td>\n",
            "<td align=\"left\" class=\"content\" valign=\"top\" width=\"75%\">\n",
            "<b>Tabled By Sponsor <a href=\"../../house/members/details/1307\">Rep. Daniel V. Beiser</a></b>\n",
            "</td></tr>\n"
          ]
        }
      ],
      "source": [
        "# Bad row\n",
        "print(rows[-1].select('td.content'), '\\n')\n",
        "\n",
        "# Good row\n",
        "print(rows[5].select('td.content'), '\\n')\n",
        "\n",
        "# How about this?\n",
        "good_rows = [row for row in rows if row.select('td.content')]\n",
        "\n",
        "print(\"Checking rows...\\n\")\n",
        "print(good_rows[0], '\\n')\n",
        "print(good_rows[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xahA2lxhayku"
      },
      "source": [
        "Looks like we found something that worked!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEdxV0eIaykv"
      },
      "source": [
        "## Loop it All Together\n",
        "\n",
        "Now that we've seen how to get the data we want from one row, as well as filter out the rows we don't want, let's put it all together into a loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "tags": [],
        "id": "SDwCBuvzaykv"
      },
      "outputs": [],
      "source": [
        "# Define storage list\n",
        "members = []\n",
        "\n",
        "# Get rid of junk rows\n",
        "valid_rows = [row for row in rows if row.select('td.content')]\n",
        "\n",
        "# Loop through all rows\n",
        "for row in valid_rows:\n",
        "    # Select only those 'td' tags with class 'detail'\n",
        "    detail_cells = row.select('td.content')\n",
        "    # Keep only the text in each of those cells\n",
        "    row_data = [cell.text for cell in detail_cells]\n",
        "    # Collect information\n",
        "    Date = row_data[0]\n",
        "    Chamber = row_data[1]\n",
        "    Action = row_data[2]\n",
        "    # Store in a tuple\n",
        "    senator = (Date, Chamber, Action)\n",
        "    # Append to list\n",
        "    members.append(senator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "75_ndyFzaykv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb92fd5-0853-4ee2-af25-a420d76f53f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ],
      "source": [
        "# Should be 61\n",
        "len(members)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seCSRd-gaykv"
      },
      "source": [
        "Let's take a look at what we have in `members`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "jX4be6nvaykv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbcbbc4-a3f0-4718-a648-861228c1c44b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n11/02/2007                                        ', '\\nHouse                                        ', '\\nFiled with the Clerk by Rep. Daniel V. Beiser'), ('\\n11/07/2007                                        ', '\\nHouse                                        ', '\\nAdded Chief Co-Sponsor Rep. John E. Bradley'), ('\\n11/07/2007                                        ', '\\nHouse                                        ', '\\nAdded Chief Co-Sponsor Rep. Robert F. Flider'), ('\\n11/07/2007                                        ', '\\nHouse                                        ', '\\nAdded Chief Co-Sponsor Rep. Elizabeth Hernandez'), ('\\n11/07/2007                                        ', '\\nHouse                                        ', '\\nAdded Chief Co-Sponsor Rep. Fred Crespo')]\n"
          ]
        }
      ],
      "source": [
        "print(members[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rxfsGqcaykv"
      },
      "source": [
        "## ü•ä  Challenge: Get `href` elements pointing to members' bills\n",
        "\n",
        "The code above retrieves information on:  \n",
        "\n",
        "- the senator's name,\n",
        "- their district number,\n",
        "- and their party.\n",
        "\n",
        "We now want to retrieve the URL for each senator's list of bills. Each URL will follow a specific format.\n",
        "\n",
        "The format for the list of bills for a given senator is:\n",
        "\n",
        "`http://www.ilga.gov/senate/SenatorBills.asp?GA=98&MemberID=[MEMBER_ID]&Primary=True`\n",
        "\n",
        "to get something like:\n",
        "\n",
        "`http://www.ilga.gov/senate/SenatorBills.asp?MemberID=1911&GA=98&Primary=True`\n",
        "\n",
        "in which `MEMBER_ID=1911`.\n",
        "\n",
        "You should be able to see that, unfortunately, `MEMBER_ID` is not currently something pulled out in our scraping code.\n",
        "\n",
        "Your initial task is to modify the code above so that we also **retrieve the full URL which points to the corresponding page of primary-sponsored bills**, for each member, and return it along with their name, district, and party.\n",
        "\n",
        "Tips:\n",
        "\n",
        "* To do this, you will want to get the appropriate anchor element (`<a>`) in each legislator's row of the table. You can again use the `.select()` method on the `row` object in the loop to do this ‚Äî similar to the command that finds all of the `td.detail` cells in the row. Remember that we only want the link to the legislator's bills, not the committees or the legislator's profile page.\n",
        "* The anchor elements' HTML will look like `<a href=\"/senate/Senator.asp/...\">Bills</a>`. The string in the `href` attribute contains the **relative** link we are after. You can access an attribute of a BeatifulSoup `Tag` object the same way you access a Python dictionary: `anchor['attributeName']`. See the <a href=\"http://www.crummy.com/software/BeautifulSoup/bs4/doc/#tag\">documentation</a> for more details.\n",
        "* There are a _lot_ of different ways to use BeautifulSoup to get things done. whatever you need to do to pull the `href` out is fine.\n",
        "\n",
        "The code has been partially filled out for you. Fill it in where it says `#YOUR CODE HERE`. Save the path into an object called `full_path`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "tags": [],
        "id": "D_uTgiqiaykw"
      },
      "outputs": [],
      "source": [
        "# # Make a GET request\n",
        "# req = requests.get('http://www.ilga.gov/senate/default.asp?GA=98')\n",
        "# # Read the content of the server‚Äôs response\n",
        "# src = req.text\n",
        "# # Soup it\n",
        "# soup = BeautifulSoup(src, \"lxml\")\n",
        "# # Create empty list to store our data\n",
        "# members = []\n",
        "\n",
        "# # Returns every ‚Äòtr tr tr‚Äô css selector in the page\n",
        "# rows = soup.select('tr tr tr')\n",
        "# # Get rid of junk rows\n",
        "# rows = [row for row in rows if row.select('td.detail')]\n",
        "\n",
        "# # Loop through all rows\n",
        "# for row in rows:\n",
        "#     # Select only those 'td' tags with class 'detail'\n",
        "#     detail_cells = row.select('td.detail')\n",
        "#     # Keep only the text in each of those cells\n",
        "#     row_data = [cell.text for cell in detail_cells]\n",
        "#     # Collect information\n",
        "#     name = row_data[0]\n",
        "#     district = int(row_data[3])\n",
        "#     party = row_data[4]\n",
        "\n",
        "#     # YOUR CODE HERE\n",
        "#     full_path = ''\n",
        "\n",
        "#     # Store in a tuple\n",
        "#     senator = (name, district, party, full_path)\n",
        "#     # Append to list\n",
        "#     members.append(senator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "# Make a GET request\n",
        "req = requests.get('https://ilga.gov/Senate/Members/List')\n",
        "src = req.text\n",
        "\n",
        "# Soup it\n",
        "soup = BeautifulSoup(src, \"lxml\")\n",
        "\n",
        "# Create empty list to store our data\n",
        "members = []\n",
        "\n",
        "# Encuentra todos los bloques de senadores\n",
        "rows = soup.select('.row.member-entry')\n",
        "\n",
        "# Loop through todos los bloques\n",
        "for row in rows:\n",
        "    # Obtener nombre\n",
        "    name_tag = row.select_one('.col-md-3 strong')\n",
        "    name = name_tag.text.strip() if name_tag else None\n",
        "\n",
        "    # Obtener partido y distrito\n",
        "    details = row.select_one('.col-md-3').get_text(separator='|', strip=True).split('|')\n",
        "    party = details[-1] if len(details) >= 2 else None\n",
        "    district = details[-2] if len(details) >= 2 else None\n",
        "    try:\n",
        "        district = int(district.replace('District ', '').strip())\n",
        "    except:\n",
        "        district = None\n",
        "\n",
        "    # Buscar enlace con MemberID\n",
        "    anchor = row.select_one('a[href*=\"MemberID\"]')\n",
        "    if anchor and 'href' in anchor.attrs:\n",
        "        href = anchor['href']\n",
        "        query = urlparse(href).query\n",
        "        member_id = parse_qs(query).get('MemberID', [None])[0]\n",
        "\n",
        "        if member_id:\n",
        "            full_path = f\"https://www.ilga.gov/senate/SenatorBills.asp?GA=98&MemberID={member_id}&Primary=True\"\n",
        "        else:\n",
        "            full_path = None\n",
        "    else:\n",
        "        full_path = None\n",
        "\n",
        "    # Guardar tupla\n",
        "    senator = (name, district, party, full_path)\n",
        "    members.append(senator)\n",
        "\n",
        "# Mostrar primeros 5\n",
        "for m in members[:5]:\n",
        "    print(m)\n",
        "\n"
      ],
      "metadata": {
        "id": "Y-8cbT-YqBbr"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "tags": [],
        "id": "l-hR7Xojaykw"
      },
      "outputs": [],
      "source": [
        "# Uncomment to test\n",
        "# members[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px3BTjMDaykw"
      },
      "source": [
        "## ü•ä  Challenge: Modularize Your Code\n",
        "\n",
        "Turn the code above into a function that accepts a URL, scrapes the URL for its senators, and returns a list of tuples containing information about each senator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "tags": [],
        "id": "EU_wpeaMaykw"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "def get_members(url):\n",
        "    return [___]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "tags": [],
        "id": "6R9mwjUIaykw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45c23ea-0042-44e4-cb30-c3baec72aeb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ],
      "source": [
        "# Test your code\n",
        "url = 'http://www.ilga.gov/senate/default.asp?GA=98'\n",
        "senate_members = get_members(url)\n",
        "len(senate_members)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDTDmFYdaykw"
      },
      "source": [
        "## ü•ä Take-home Challenge: Writing a Scraper Function\n",
        "\n",
        "We want to scrape the webpages corresponding to bills sponsored by each bills.\n",
        "\n",
        "Write a function called `get_bills(url)` to parse a given bills URL. This will involve:\n",
        "\n",
        "  - requesting the URL using the <a href=\"http://docs.python-requests.org/en/latest/\">`requests`</a> library\n",
        "  - using the features of the `BeautifulSoup` library to find all of the `<td>` elements with the class `billlist`\n",
        "  - return a _list_ of tuples, each with:\n",
        "      - description (2nd column)\n",
        "      - chamber (S or H) (3rd column)\n",
        "      - the last action (4th column)\n",
        "      - the last action date (5th column)\n",
        "      \n",
        "This function has been partially completed. Fill in the rest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "tags": [],
        "id": "At6AzzDNaykw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "1903c7d6-4d0a-4535-f566-259e7f99f154"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-294-3384773414.py, line 8)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-294-3384773414.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    bill_id =\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "def get_bills(url):\n",
        "    src = requests.get(url).text\n",
        "    soup = BeautifulSoup(src)\n",
        "    rows = soup.select('tr')\n",
        "    bills = []\n",
        "    for row in rows:\n",
        "        # YOUR CODE HERE\n",
        "        bill_id =\n",
        "        description =\n",
        "        chamber =\n",
        "        last_action =\n",
        "        last_action_date =\n",
        "        bill = (bill_id, description, chamber, last_action, last_action_date)\n",
        "        bills.append(bill)\n",
        "    return bills"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Cdm6-Susaykw"
      },
      "outputs": [],
      "source": [
        "# Uncomment to test your code\n",
        "# test_url = senate_members[0][3]\n",
        "# get_bills(test_url)[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHNmqYMmaykw"
      },
      "source": [
        "### Scrape All Bills\n",
        "\n",
        "Finally, create a dictionary `bills_dict` which maps a district number (the key) onto a list of bills (the value) coming from that district. You can do this by looping over all of the senate members in `members_dict` and calling `get_bills()` for each of their associated bill URLs.\n",
        "\n",
        "**NOTE:** please call the function `time.sleep(1)` for each iteration of the loop, so that we don't destroy the state's web site."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "xMgnkdYeaykw"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "w1fVJKlSaykw"
      },
      "outputs": [],
      "source": [
        "# Uncomment to test your code\n",
        "# bills_dict[52]"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b6f9fe9f4b7182690503d8ecc2bae97b0ee3ebf54e877167ae4d28c119a56988"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}